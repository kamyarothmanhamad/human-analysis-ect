{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECT Pipeline for Human Point Cloud Analysis\n",
    "\n",
    "Import required modules for ECT computation and dataset handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ect import compute_ect_for_label\n",
    "from dataset import HumanPointCloudDataset, analyze_dataset_info, compare_dataset_samples\n",
    "from pc_vis_utils import display_part_pc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Paths\n",
    "\n",
    "Configure paths to the HDF5 files containing vertices and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote server paths\n",
    "# vertices_path = \"./data/reoriented_vertices.hdf5\"\n",
    "# labels_path = \"./data/cihp_vertex_labels.hdf5\"\n",
    "\n",
    "# local machine paths\n",
    "vertices_path = \"/media/kamyar/669AE7069AE6D19B/Users/othma/Downloads/reoriented_vertices.hdf5\"\n",
    "labels_path = \"/media/kamyar/669AE7069AE6D19B/Users/othma/Downloads/cihp_vertex_labels.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Initialize the human point cloud dataset with normalization enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HumanPointCloudDataset(\n",
    "    vertices_hdf5_path=vertices_path,\n",
    "    labels_hdf5_path=labels_path,\n",
    "    normalize=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Exploration\n",
    "\n",
    "Extract labels for sample 22 to examine the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels in the Training sample 22:\n",
      "Total number of vertices: 1499997\n",
      "Total number of unique labels: 10\n",
      "Labels: [2, 5, 9, 10, 12, 13, 14, 15, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "# Get labels for a specific sample (e.g., sample 22)\n",
    "sample_labels = dataset.get_sample_v_l(22, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Filtering and Visualization\n",
    "\n",
    "Filter points by specific label (label 2) and visualize the filtered point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_label(points, labels, target_label):\n",
    "    \"\"\"\n",
    "    Filter points and labels to keep only those with the specified label.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : array-like\n",
    "        The feature data (e.g., numpy array, pandas DataFrame)\n",
    "    labels : array-like\n",
    "        The corresponding labels for each point\n",
    "    target_label : any\n",
    "        The specific label to filter for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered_points : array-like\n",
    "        Points corresponding to the target label\n",
    "    filtered_labels : array-like\n",
    "        Labels corresponding to the target label (all will be target_label)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays with explicit copy parameter\n",
    "    if hasattr(points, 'numpy'):  # Check if it's a PyTorch tensor\n",
    "        points_arr = points.numpy()\n",
    "    else:\n",
    "        points_arr = np.asarray(points)\n",
    "        \n",
    "    if hasattr(labels, 'numpy'):  # Check if it's a PyTorch tensor\n",
    "        labels_arr = labels.numpy()\n",
    "    else:\n",
    "        labels_arr = np.asarray(labels)\n",
    "    \n",
    "    # Create a mask for the target label\n",
    "    mask = labels_arr == target_label\n",
    "    \n",
    "    # Filter points and labels using the mask\n",
    "    filtered_points = points_arr[mask]\n",
    "    filtered_labels = labels_arr[mask]\n",
    "    \n",
    "    return filtered_points, filtered_labels\n",
    "\n",
    "idx  = 2\n",
    "label_id = 2\n",
    "sample = dataset[22]\n",
    "\n",
    "points = sample.x\n",
    "labels = sample.y\n",
    "\n",
    "filtered_points, filtered_labels = filter_by_label(points, labels, label_id)\n",
    "display_part_pc(filtered_points, filtered_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Sample Visualization\n",
    "\n",
    "Display the complete point cloud for sample 22 with default view settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Training Sample 22\n"
     ]
    }
   ],
   "source": [
    "dataset.visualize_sample(idx, train=True, with_normals=False, with_default_view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECT Computation\n",
    "\n",
    "Compute the Euler Characteristic Transform for label 2 in sample 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ECT for label 2: 277364 points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ect_features': tensor([[3.7276e-05, 4.1520e-05, 5.7453e-06,  ..., 1.2204e-04, 6.5607e-05,\n",
       "          9.3856e-05],\n",
       "         [6.2455e-05, 6.9565e-05, 9.6263e-06,  ..., 2.0445e-04, 1.0992e-04,\n",
       "          1.5724e-04],\n",
       "         [1.0464e-04, 1.1655e-04, 1.6129e-05,  ..., 3.4249e-04, 1.8414e-04,\n",
       "          2.6342e-04],\n",
       "         ...,\n",
       "         [9.8627e-01, 9.8833e-01, 9.1634e-01,  ..., 9.9653e-01, 9.9086e-01,\n",
       "          9.9560e-01],\n",
       "         [9.9243e-01, 9.9357e-01, 9.4744e-01,  ..., 9.9856e-01, 9.9451e-01,\n",
       "          9.9769e-01],\n",
       "         [9.9582e-01, 9.9635e-01, 9.6761e-01,  ..., 9.9952e-01, 9.9779e-01,\n",
       "          9.9882e-01]]),\n",
       " 'num_points': 277364,\n",
       " 'label': 2,\n",
       " 'sample_idx': 22,\n",
       " 'filtered_points': array([[ 0.05305869,  0.943851  ,  0.20144667],\n",
       "        [ 0.0445837 ,  0.9381565 ,  0.20642935],\n",
       "        [ 0.0548827 ,  0.93958014,  0.19948919],\n",
       "        ...,\n",
       "        [ 0.04949963,  0.75878024, -0.11344051],\n",
       "        [ 0.04785357,  0.75664485, -0.11326256],\n",
       "        [ 0.04480614,  0.75806844, -0.1127287 ]],\n",
       "       shape=(277364, 3), dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ect_for_label(dataset, sample_idx=22, target_label=2, train=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
